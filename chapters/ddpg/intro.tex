The goal of this chapter is to dive deep into an actor-critic algorithm to build up in-depth knowledge about every aspect of this reinforcement learning approach. As \cite{tim2018} points out, this is a necessary step towards actually using these methods to their full potential because in case of a failure the researcher has deep understanding and can bring up ideas on how to tweak certain aspects around the whole learning setup.
\par
To achieve said objective, we will take a very close look at an algorithm called \textit{Deep Deterministic Policy Gradient} (DDPG). Every element of this algorithm has its own sub-chapter where slices of the pseudo code from the original DDPG paper, published by \cite{lillicrap2019continuous}, will be included and discussed. The entire pseudo code of the algorithm can be found in subchapter \ref{subchap:pseudo}.

