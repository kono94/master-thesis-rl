The performance metric is the same as the one used in the synthetic experiments which is the average euclidean distance, defined by \ref{eq:euclid}.
\par
For the first set of experiments, we use behavioral closing with the same network architecture and learning rate which yielded the best results in the synthetic experiment in subchapter \ref{subchap:applyBC}. The network of $n_h^1=256$, $n_h^2=128$ and $n_h^3=64$ was trained for X epochs with a learning rate of $\alpha=10^{-5}$ for every dataset which proceeds following outcome:

// insert table


// we see (difference COG to course), new approach


Assumption that more neurons can be better for tanker dataset.

//nope



// higher frequency (instead of 10)
// lower frequency?

//DDPG for fun


// Time for one prediction

In the next chapter we take the verkleinerung of the dataset to the extreme and try to fit to one and two trajectories alone. 