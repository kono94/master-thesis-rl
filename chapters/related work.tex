After a profound literature research, we can divide the related work into two sub categories. Those include the topics of building a framework for anomaly detection in the maritime domain and the general application of machine learning in path planning or prediction.

%different approaches to reinforcement learning such as inverse- and offline reinforcement learning and the ongoing work done in the field of deep reinforcement learning.
\par 
\paragraph{Anomaly detection of vessel behavior}
Building a maritime awareness system that operates in near real time by processing huge amounts of data from all kinds of different sources (AIS, radar systems, satellites, etc.) is not a simple task. The work of \cite{tsogas2019geospatial} presents a system architecture named Geospatial Complex Event Processing Service (TRITON) that is capable of handling large volumes of incoming events using ActiveMQ as message broker and PostgreSQL as database, which is optimized for storing and querying geospatial information. By using the Event Processing Language (EPL), the service is also able to detect abnormal vessel behavior. Though the set of specific rules (vessel entering, exiting, crossing, moving away or approaching areas) have to be defined by domain experts \cite[p.~4]{tsogas2019geospatial} which is a critical limitation of the detector. The authors themselves are thus mentioning the usage of reinforcement and unsupervised learning in future work \cite[p.~9]{tsogas2019geospatial}.
\par 
The general approach of using geospatial data like AIS to learn motion patterns, that are eventually used to predict vessel paths and detect anomalies, is not a novelty. Instead of employing handcrafted rules, the highly cited work by \cite{ristic2008statistical} uses historical AIS data to extract motion patterns to train an anomaly detector by applying statistical methods such as adaptive kernel density estimation and particle filters. A motion pattern in this connection is defined by kinematic information including ship location and velocity but also by at least one mandatory attribute of information—the ship's origin—to distinguish between overlapping motion patterns \cite[p.~2]{ristic2008statistical}. This could be an interesting factor when designing a suitable state representation to fulfill the Markov property.
\par 
In a recent summary of the related literature, \cite{zhang2020analysis} analyze the research trends of vessel abnormal behavior detection of the past ten years. They found that earlier work concentrated on the detection of just abnormal tracking positions mainly based on statistical methods by almost exclusively using movement data (position, speed, heading) of the perspective of a single ship (pp.~47-48). In contrast, more recent approaches try to detect anomalies in specific situations by including contextual information such as meteorological data, the interaction between ships, the perception of ship motion status (identification of fishing operations, ship towing push or ship gathering) and video data \cite[p.~50]{zhang2020analysis}. The system presented by \cite{solano2021detection} is one concrete example of the utilizing of video data in order to detect abnormal vessel behavior. In general, the usage of non-kinematic features should be considered to eventually construct a sophisticated anomaly detector that  truly has a sense of situational awareness. In their work, \cite{zhang2020analysis} conclude that detectors of abnormal vessel behavior face major problems, such as poor comprehensiveness (cannot specify abnormality type and degree), difficulties with huge amounts of data due to the complexity of their algorithms and high false alarm rates because of subjectively chosen thresholds (p.~52).
\par 
As mentioned in chapter \ref{chap:intro}, the term \anf{anomaly} can mean many things, even in the conjunction of AIS data. Detecting abnormal vessel behavior solely based on the trajectory is the main focus of this thesis, but there are other types as well. \cite{singh2020effectiveness} who are colleagues at the sister institute in Neustrelitz, near Berlin, focus on malicious and intentional AIS on-off switching (OOS) anomalies. In their paper they compare the performance of various AI techniques including support vector machines, k-nearest neighbors, decision trees, artificial neural networks and naive Bayesian towards detecting the AIS
OOS anomalies using real historical AIS data (p.~1). The results (99.9\% accuracy when using an artificial neural network \cite[p.~7]{singh2020effectiveness}) suggest that this specific task can be labeled as solved. 


\paragraph{Path prediction}
To predict the trajectories of vessels, \cite{liu2019vessel} use support vector regression (SVR) in conjunction with an algorithm called ACDE for  parameter optimization. ACDE stands for \anf{differential evolution based on adaptive control parameters} and is an improved version of the differential evolution algorithm, which tackles stochastic parallel optimization and is based on evolutionary ideas in the form of genetic algorithms \cite[pp.~1-3]{thangaraj2009simple}. In their work, \cite{liu2019vessel} also present algorithms on how to extract single trajectories from the AIS data using the unique maritime mobile service identification (MMSI) numbers and how to clean, de-noise and normalize the AIS data (pp.~9-11). As multivariable input or in the context of reinforcement learning this can also be called \textit{state}, the authors of this paper are using Unix timestamps, longitude, latitude, course, and speed over ground of the ship (p.~11). We can redefine their input as state definition for a better overview, where $COG_t$ and $SOG_t$ are course and speed over ground respectively:
\begin{equation}
S_t = \{lon_t, lat_t, COG_t, SOG_t, Timestamp_t\}
\end{equation}
Four of those previous states plus the timestamp of the next moment $T_{t+1}$ are the true input for two separate SVR models, one predicts the longitude $lon_{t+1}$ and the other predicts the latitude $lat_{t+1}$ for just one moment in advance \cite[p.~11]{liu2019vessel}. Predicting just the next timestamp in advance, this method might be not suitable in terms of forecasting a complete vessel trajectory because of the major concern that this model will accumulate error if a prediction output is used as input for a larger forecasting window.
\par
In a recent published paper, \cite{venskus2021unsupervised} tackle the exact same topic of this thesis, that is the prediction of vessel trajectories based on historical AIS data in an unsupervised manner. They use an LSTM autoencoder that learns to reconstruct vessel paths for the next $X$ timestamps (p.~724). Furthermore, the authors utilize a method proposed by \cite{cruz2019} to eventually generate a prediction region that is learned by two supplementary LSTM autoencoders in addition to the  most like-hood forecast of the original autoencoder that learns single trajectories (p.~725). Predicting a potential region that vessels under normal behavior would navigate in, makes anomaly detection trivial by just checking if the prognosticated path is inside the region that is considered \anf{normal}. Nevertheless, a major constraint of this method is the needed input sequence of past $X$ timestamps to start forecasting the next $X$ timestamps.
\par 
\cite{perera2012maritime} introduce a framework to monitor maritime traffic by constructing three modules. The first module consists of an artificial neural network that detects and tracks multiple vessels, while the second and third modules are used to estimate the vessel states and forecast the navigational trajectory by using an extended Kalman filter \cite[p.~1]{perera2012maritime}. 
\par 
A completely different approach is presented by \cite{6198334} who take advantage of the genetic algorithm in conjunction with randomly generated Bézier curves to solve the path planning of  autonomous unmanned aerial vehicles (UAVs) in previously defined environments~(p.~1). Besides, they achieve quasi-linear speedup in relation to the number of CPU cores by using a parallel programming paradigm called \anf{single-program,
multiple-data} (pp.~7-8). Although the authors themselves state that the planning takes 10 seconds while running on eight cores in parallel, they still make the conclusion that \anf{real-time path planning for UAVs is possible} \cite[p.~9]{6198334}. However, we see this computational cost as a critical limitation of classic genetic algorithms in general. Even though vessel planning cuts one dimension as the prediction of UAVs paths takes place in a 3D domain, we still make the assumption that this approach is not suitable for future visions of calculating vessel paths of hundreds of ships in near real-time. 
\par 
Entering the field of deep reinforcement learning, we can notice that most works are related to the control or path planning of unmanned vehicles (land, water, or air) without focusing specifically on anomaly detection but rather control. \cite{etemad2020using} and \cite{zare2021continuous} for example utilize the classic Floyd–Warshall algorithm as path-planner and apply deep Q-learning or Deep Deterministic Policy Gradient (DDPG) respectively to tackle obstacle avoidance for unmanned surface vehicle (USV). In this case, deep reinforcement learning is used to evaluate the current situation (local view) on the USV's path and makes short-term decisions to avoid collisions (p.~8).

\par
The usage of Deep RL not only as supportive mechanism for short-term decision-making but rather as full control algorithm for intelligent vehicles is the main field of application for reinforcement in general and, 
as a consequence, is ubiquitous in the literature. \cite{wang2018reinforcement} for instance, take advantage of DDPG to control an autonomous underwater vehicle (AUV) in an under-ice environment that eventually learns the long-term reward of reducing the field uncertainty and the AUV mobility cost (p.~17). Another example is the work of \cite{s18092905} whose agent represents a land vehicle. They extract an abstract model of the real environment to then teach the agent driving maneuvers like overtaking, following a curve, ramp driving as well as staying in lane (pp.~1,4). As the agent is trained by the DDPG algorithm, it implicitly learns to drive on or near the desired path. This is mainly accomplished by defining the desired path and using the difference between the current posture and the desired one as part of the reward signal \cite[p.~4]{s18092905}. After training the agent in the virtual environment, the authors transfer their model and their \anf{end-to-end trajectory planning} (p.~17) to a real world scenario by letting the agent control a self-driving bus (pp.~18-19).
\par
Staying in the maritime domain, we can identify the inventiveness of crewless autonomous ship systems as the closest research topic to the one of this thesis. In this field, \cite{s20020426} present a paper that uses the actor-critic algorithm DDPG to select actions which navigate a vessel on the fastest way to the target destination while also taking into account ship encounters (pp.~13-14). The important parts of their path planning module are the environment and the reward function. For the environment, they choose a combination of two components. The first one is the \anf{Ship Action Controller} which converts the model output to an actual action that the unmanned ship should take (p.~15). The second one is the so called \anf{Ship navigation information fusion module} which is able to receive data from GPS, AIS, depth sounder and anemometer to construct a state that holds information about the ship itself, obstacles and the target point (p.~10). The reward signals are built by transforming the crew's experience and the navigation rules defined by COLREGS \cite[]{COLREG} into navigation restriction areas \cite[p.~14]{s20020426}. Crossing a restricted area or colliding with an obstacles results in a negative reward. Additionally, the inverse of the distance between the agent and the target point is also granted as reward signal \cite[p.~14]{s20020426}. The results displayed by the authors are promising as the agent not only learns to get to the destination on the shortest path while avoiding obstacles but also reacts and adopts to multiple ships on its path
\cite[pp.~21-26]{s20020426}.
\par 
Instead of learning online by interacting with an environment, it is also possible to learn offline by using historical AIS data. This approach is followed by \cite{westerlund2021learning} who uses offline reinforcement learning. The goal of his master thesis is to make an agent (the vessel) learn to get to a destination based on previously sampled data from a simulator. The simulator outputs a series of AIS data points representing the taken vessel trajectories, which is used as data set. Here, the state is defined by latitude, longitude, speed over ground, course over ground, and most importantly the rudder angle while the action space only consists of the heading the ship should have at the next timestamp \cite[pp.~30-33]{westerlund2021learning}. To fully build the necessary tuples that get fed into the replay buffer $(s_t, a_t, r_{t+1}, s_{t+1})$, the author calculates the reward based on the difference between the current position and the targeted one (p.~27). Although the presented results show that it would generally be possible to apply offline reinforcement learning to the path planning problem of vessels, the author himself states that performance is \anf{limited by the size and diversity of the dataset}(p.~40) as the generalization outside the trained area is deficient.
\par
The previously cited works are better categorized as \anf{path finders}, which means that their reward function is built around finding the best or potential new route to a destination. This lies in the nature of reinforcement learning, being mainly used in control problems that try to come up with a policy that has learned the underlying dynamics of an environment. Even if the training data is not sampled online but generated in the past (as in the work  from \cite{westerlund2021learning}), the reward function is still defining the semantic of the goal, which is very different from the goal of learning representative trajectories for future anomaly detection. For this specific setting, the term \anf{path follower} might be more fitting. We found a paper from \cite{martinsen2018curved} which focuses exactly on this topic of following of a predefined curved path by a vessel. In their work they use DDPG and a Gaussian reward function that is mainly built from a cross-track error which tells how far away the vessel is from the predefined path \cite[p.~3]{martinsen2018curved}. 